# CellViT++ Project Documentation

## Overview
CellViT++ëŠ” ì„¸í¬ ê²€ì¶œ ë° ë¶„ë¥˜ë¥¼ ìœ„í•œ Vision Transformer ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ë³¸ ë¬¸ì„œëŠ” í”„ë¡œì íŠ¸ì˜ êµ¬ì¡°ì™€ ì‚¬ìš©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## Model Architecture

### Backbone Models
CellViT++ëŠ” ë‹¤ì–‘í•œ ë²„ì „ì˜ Vision Transformer ê¸°ë°˜ ë°±ë³¸ì„ ì œê³µí•©ë‹ˆë‹¤:
- CellViT256
- CellViTSAM
- CellViTUNI
- CellViTVirchow
- CellViTVirchow2

### Classifier Head
- êµ¬ì¡°: Linear Classifier
- ì…ë ¥: Backboneì˜ hidden dimension
- ì¶œë ¥: ë°ì´í„°ì…‹ë³„ í´ë˜ìŠ¤ ìˆ˜

---

## Pre-trained Models

### Backbone Checkpoints
```
ğŸ“ checkpoints/
â””â”€â”€ cellvit_sam_h.pth  # Google Driveì—ì„œ ë‹¤ìš´ë¡œë“œ í•„ìš”
```

### Classifier Checkpoints
```
ğŸ“ checkpoints/classifier/sam-h/
â”œâ”€â”€ consep.pth         # 4 classes: Other, Inflammatory, Epithelial, Spindle-Shaped
â”œâ”€â”€ lizard.pth        # 6 classes: Neutrophil, Epithelial, Lymphocyte, Plasma, Eosinophil, Connective
â”œâ”€â”€ midog.pth         # 2 classes: Mitotic, Non-Mitotic
â”œâ”€â”€ nucls_main.pth
â”œâ”€â”€ nucls_super.pth
â”œâ”€â”€ ocelot.pth        # 2 classes: Other Cell, Tumor Cell
â””â”€â”€ panoptils.pth     # 4 classes: Other, Epithelial, Stromal, TILs
```

---

## Supported Datasets

### Built-in Datasets
- CoNSeP
- Ocelot
- SegPath
- MIDOG
- NuCLS
- Panoptils
- Lizard

### Dataset Features
- Albumentations ê¸°ë°˜ ë°ì´í„° ì¦ê°•
- ì •ê·œí™” ì˜µì…˜
- ë°ì´í„°ì…‹ë³„ ì „ìš© Dataset í´ë˜ìŠ¤

---

## Training Process

### Basic Training Flow
```python
# 1. Load backbone model
cellvit_model = CellViT256.from_pretrained(checkpoint_path)
cellvit_model.eval()  # Feature extractor mode

# 2. Initialize classifier
classifier = LinearClassifier(
    input_dim=cellvit_model.hidden_dim,
    num_classes=num_classes
)

# 3. Setup training
optimizer = AdamW(classifier.parameters())
criterion = CrossEntropyLoss(weight=class_weights)

# 4. Initialize trainer and train
trainer = CellViTHeadTrainer(
    model=classifier,
    cellvit_model=cellvit_model,
    loss_fn=criterion,
    optimizer=optimizer
)
```

### Key Training Features
- âœ… Mixed Precision Training
- âœ… Gradient Accumulation
- âœ… Weighted Loss (í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬)
- âœ… Early Stopping
- âœ… Learning Rate Scheduling
- âœ… WandB ëª¨ë‹ˆí„°ë§

---

## Configuration

### Example Configuration File
```yaml
# Model configuration
model:
  name: "cellvit"
  backbone: "vit_h"
  pretrained_path: "checkpoints/cellvit_sam_h.pth"
  num_classes: 5

# Training configuration
training:
  batch_size: 32
  gradient_accumulation_steps: 4
  epochs: 100
  learning_rate: 0.0001
  weight_decay: 0.0001
  optimizer: "AdamW"
  scheduler: "cosine"
  class_weights: [...]

# Data configuration
data:
  dataset_path: "Dataset_Old"
  train_filelist: "splits/train_split.csv"
  val_filelist: "splits/val_split.csv"
  normalize_stains: true
  augmentation:
    enabled: true
```

---

## HER2 Dataset Application

### Dataset Characteristics
| Class | Distribution |
|-------|-------------|
| 0     | 12.4%       |
| 1+    | 14.6%       |
| 2+    | 6.7%        |
| 3+    | 17.2%       |
| NT    | 49.1%       |

### Recommended Settings
1. **Base Model**: consep ë¶„ë¥˜ê¸° ê¸°ë°˜ fine-tuning
2. **Loss Function**: í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ ê³ ë ¤í•œ weighted loss
3. **Data Augmentation**: ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì¦ê°• ê¸°ë²• ì ìš©

---

## Project Structure
```
CellViT-plus-plus/
â”œâ”€â”€ cellvit/
â”‚   â”œâ”€â”€ models/          # ëª¨ë¸ êµ¬í˜„
â”‚   â”œâ”€â”€ training/        # í•™ìŠµ ê´€ë ¨ ì½”ë“œ
â”‚   â””â”€â”€ utils/           # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ checkpoints/         # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â”‚   â””â”€â”€ classifier/
â”‚       â””â”€â”€ sam-h/
â”œâ”€â”€ configs/             # ì„¤ì • íŒŒì¼
â”œâ”€â”€ logs/                # í•™ìŠµ ë¡œê·¸
â””â”€â”€ Dataset_Old/         # ë°ì´í„°ì…‹
```

---

## Requirements
- CUDA-capable GPU (24GB VRAM ì´ìƒ ê¶Œì¥)
- 32GB RAM ì´ìƒ
- 30GB ë””ìŠ¤í¬ ê³µê°„
- 16 CPU ì½”ì–´ ì´ìƒ

---

## References
- [CellViT++ GitHub Repository](https://github.com/TIO-IKIM/CellViT-plus-plus)
- [Original Paper](https://arxiv.org/abs/2501.05269) 