{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Lizard Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from https://warwick.ac.uk/fac/cross_fac/tia/data/\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataset structure\n",
    "# sort the images accordingly into the split folders\n",
    "\n",
    "# fold_1\n",
    "#   images ->       images as .png with x20 magnification (original size, just copy)\n",
    "#   labels ->       labels as .mat with x20 magnification (original size, just copy)\n",
    "#   tiff_resized ->         images as .tiff with x40 magnification (resize to x40 with vips, see below)\n",
    "#   predictions-cellvit ->  predictions for each cellvit variant (subfolder) with .pt graphs inside\n",
    "\n",
    "# do the same for fold_2 and fold_3\n",
    "\n",
    "# filelist for the images can be found in each split folder in the ./logs/Datasets/Lizard folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create resized files with vips\n",
    "fold_path = Path(\"path/to/splitted/dataset/fold_x\") # chnage to correct path and fold number\n",
    "input_dir = fold_path / \"images\"\n",
    "output_dir = fold_path / \"tiff_resized\"\n",
    "\n",
    "for img_path in input_dir.glob(\"*.png\"):\n",
    "    input_file = str(img_path.resolve())\n",
    "    output_file = str(output_dir / img_path.name).replace(\".png\", \".tiff\")\n",
    "    !vips tiffsave $input_file $output_file --tile --tile-width 256 --tile-height 256 --pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference for Lizard with cellvit, as we train on preextracted features (lizard preextracted)\n",
    "# either extract features with cellvit or download the preextracted features here: \n",
    "#\n",
    "#   https://drive.google.com/drive/folders/17N7lHSBwWUaCYdtnCGdGGFN2vWggBXdf?usp=sharing\n",
    "#\n",
    "# place them inside the folds\n",
    "#  predictions-cellvit \n",
    "#     SAM-H \n",
    "#       crag_2.pt\n",
    "#       ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplary configs can be found in the log folder:\n",
    "# ./logs/Classifiers/Lizard\n",
    "\n",
    "# python3 ./cellvit/train_cell_classifier_head.py --config /path/to/your/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate with lizard-evaluation metrics\n",
    "\n",
    "# python3 cellvit/training/evaluate/inference_cellvit_experiment_lizard.py --help\n",
    "# usage: inference_cellvit_experiment_lizard.py [-h] [--logdir LOGDIR] [--dataset_path DATASET_PATH] [--network_name {SAM-H,UNI,ViT256}]\n",
    "#                                               [--split {fold_1,fold_2,fold_3,test}] [--gpu GPU] [--use_histomics] [--norm_path NORM_PATH]\n",
    "\n",
    "# Perform CellViT-Classifier inference for Lizard\n",
    "\n",
    "# options:\n",
    "#   -h, --help            show this help message and exit\n",
    "#   --logdir LOGDIR       Path to the log directory with the trained head. (default: None)\n",
    "#   --dataset_path DATASET_PATH\n",
    "#                         Path to the Lizard dataset (default: /home/jovyan/cellvit-data/Lizard-CellViT-Histomics)\n",
    "#   --network_name {SAM-H,UNI,ViT256}\n",
    "#                         Specify the network name. Choices are: 'SAM-H', 'UNI', 'ViT256' (default: None)\n",
    "#   --split {fold_1,fold_2,fold_3,test}\n",
    "#                         Specify the fold name. Choices are: 'fold_1', 'fold_2', 'fold_3', 'test (default: None)\n",
    "#   --gpu GPU             Number of CUDA GPU to use (default: 0)\n",
    "#   --use_histomics       Flag to indicate whether to use histomics features (default: False)\n",
    "#   --norm_path NORM_PATH\n",
    "#                         Path to the training normalization folder if using histomics features (default: None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellvit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
