{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare MIDOG++ Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Citation:**\n",
    "Aubreville, Marc; Wilm, Frauke; Stathonikos, Nikolas; Breininger, Katharina; Donovan, Taryn; Jabari, Samir; et al. (2023). MIDOG++: A Comprehensive Multi-Domain Dataset for Mitotic Figure Detection. figshare. Collection. https://doi.org/10.6084/m9.figshare.c.6615571.v1\n",
    "\n",
    "**Download and dataset preparation**\n",
    "As the images in the MIDOG dataset are rather large, we first preexctract the cell-graphs by applying CellViT and then train the classification module solely on the graphs (*.pt files). Due to the CCO license we are pleased to share the annotations along this repository.\n",
    "\n",
    "If you want to perform all steps, you need to have at least 300 GB free disk space.\n",
    "\n",
    "1. Please download the dataset here: https://springernature.figshare.com/collections/MIDOG_A_Comprehensive_Multi-Domain_Dataset_for_Mitotic_Figure_Detection/6615571\n",
    "   Just download the figures (*.tiff) and place them in a folder called `images_raw`. We provide the following files with changes marked here:\n",
    "        - dataset_xvalidation.csv: added slide mpp in x and y direction\n",
    "        - midog.json: Same file as MIDOG++.json, but renamed\n",
    "        - midog_indent.json: Same file as MIDOG++.json, but with intendations for better readability (human)\n",
    "        - gt_dataset.json: JSON-File with Mitotic Figures (only Mitotic Figures!) for every image in the dataset\n",
    "        - gt_test.json: JSON-File with Mitotic Figures (only Mitotic Figures!), just for the images in the test set\n",
    "        - label_map.yaml: Label-Map\n",
    "        - filelist.csv: Filelist with all WSI paths of MIDOG++ for CellViT extraction\n",
    "    If you needs help with the download, check out this script from the authors of the dataset: https://github.com/DeepMicroscopy/MIDOGpp/blob/main/Setup.ipynb. We just needed to replace the download link with https://springernature.figshare.com/ndownloader/files/{file} in the notebook. The dataset size is around 65GB. We tried to replicate the split (train-val) by following the guidelines in the training script of https://github.com/DeepMicroscopy/MIDOGpp/blob/8b15a5af4508953ca67f8cbe6a4c19e724cf4431/training.py. The test split is externally defined by the authors which we followed. \n",
    "2. The dataset structure should be:\n",
    "   \n",
    "        ```bash\n",
    "        ./\n",
    "        ├── images_raw                  # images downloaded -> No pyramid (single plane tiff file)\n",
    "        │   ├── 001.tiff\n",
    "        │   ├── 002.tiff\n",
    "        │   ...\n",
    "        │   └── 553.tiff\n",
    "        ├── split                       # corresponding split files\n",
    "        │   ├── leave-one-out\n",
    "        │   ├── single-domain\n",
    "        │   └── test_files\n",
    "        ├── datasets_xvalidation.csv    # please use our file!\n",
    "        ├── gt_dataset.json             # please use our file!\n",
    "        ├── gt_test.json                # please use our file!\n",
    "        ├── midog.json                  # please use our file!\n",
    "        ├── midog_indent.csv            # please use our file!\n",
    "        ├── label_map.yaml            # please use our file!\n",
    "        └── filelist.csv            # please use our file!\n",
    "        ```\n",
    "3. Convert tiff files to pyramid-tiff images using vips and store them in the `images` folder. Change the paths in the `convert.sh` script to your local paths and run the script.\n",
    "   Be carefull, this adds additional 100GB to your local disk.\n",
    "4. Extract graphs. Exchange the checkpoint with the cellvit model, change the outdir and adapt the paths in the filelist.csv before running:\n",
    "\n",
    "         ```bash\n",
    "         python3 ./cellvit/detect_cells.py \\\n",
    "            --model ./cellvit/checkpoints/SELECT_YOUR_CHECKPOINT \\ # exchange, e.g. ./checkpoints/CellViT-SAM-H-x40-AMP.pth\n",
    "            --outdir /path/to/MIDOG++/Dataset/graphs/model \\ # exchange, e.g., ./logs/Datasets/MIDOG++/graphs/SAM-H\n",
    "            --batch_size 4 \\\n",
    "            --graph \\\n",
    "            process_dataset \\ \n",
    "            --filelist /path/to/MIDOG++/filelist.csv \\ # exchange, e.g., ./logs/Datasets/MIDOG++/filelist.csv\n",
    "            --wsi_extension tiff\n",
    "         ```\n",
    "5. Define your configs and train. An example is given in the folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 ./cellvit/train_cell_classifier_head.py --config /path/to/your/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General overview of the CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate with MIDOG-evaluation metrics\n",
    "# python3 ./cellvit/training/evaluate/inference_cellvit_experiment_midog.py --help\n",
    "#\n",
    "# usage: inference_cellvit_experiment_midog.py [-h] [--logdir LOGDIR] [--graph_path GRAPH_PATH] [--test_filelist TEST_FILELIST] [--gt_json GT_JSON]\n",
    "#                                              [--x_valid_path X_VALID_PATH] [--threshold THRESHOLD] [--bbox_radius BBOX_RADIUS] [--comment COMMENT] [--gpu GPU]\n",
    "#                                              [--image_path IMAGE_PATH] [--validation VALIDATION]\n",
    "                                             \n",
    "# Perform CellViT-Classifier inference for MIDOG dataset. Differing to all other datasets, as the MIDOG dataset contains WSI-like sections the preextracted graphs (from\n",
    "# cellvit/detect_cells.py) are used for inference and passed to the CellViT-Classifier-Head. Be careful to use the correct graph folder!\n",
    "\n",
    "# options:\n",
    "#   -h, --help            show this help message and exit\n",
    "#   --logdir LOGDIR       Path to the log directory with the trained head. (default: None)\n",
    "#   --graph_path GRAPH_PATH\n",
    "#                         Path to the MIDOG dataset with the preextracted graphs for this CellViT-Architecture. Be careful about choosing the correct CellViT-\n",
    "#                         Architecture for the graph folder. Possible models are: CellViT-256, CellViT-SAM-H, CellViT-UNI (default: None)\n",
    "#   --test_filelist TEST_FILELIST\n",
    "#                         Path to the test filelist for the MIDOG dataset. (default: None)\n",
    "#   --gt_json GT_JSON     Path to the ground truth json test file for the MIDOG dataset. (default: None)\n",
    "#   --x_valid_path X_VALID_PATH\n",
    "#                         Path to the x_valid.csv file for the MIDOG dataset. (default: None)\n",
    "#   --threshold THRESHOLD\n",
    "#                         Threshold for classification. Default is 0.85. (default: 0.85)\n",
    "#   --bbox_radius BBOX_RADIUS\n",
    "#                         Radius for merging cells. Default is 0.01125. (default: 0.01125)\n",
    "#   --comment COMMENT     Comment for the inference run. (default: None)\n",
    "#   --gpu GPU             Number of CUDA GPU to use (default: 0)\n",
    "#   --image_path IMAGE_PATH\n",
    "#                         Path to the image folder for the MIDOG dataset. Just use if you want to store plots. (default: None)\n",
    "#   --validation VALIDATION\n",
    "#                         If set, the validation set is used for inference and optimal thresholds calculated. (default: None)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Validation to find classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 ./cellvit/training/evaluate/inference_cellvit_experiment_midog.py \\\n",
    "#     --logdir /Path/to/your/run/log \\\n",
    "#     --graph_path /Path/to/the/graphs \\\n",
    "#     --test_filelist /Path/to/the/validation/split \\ # e.g. ./logs/Datasets/MIDOG++/split/single-domain/all/valid_0.csv\n",
    "#     --gt_json /Path/to/gt_dataset.json \\\n",
    "#     --x_valid_path /Path/to/datasets_xvalidation.csv \\\n",
    "#     --validation True\n",
    "#     --comment validation\n",
    "# IT IS IMPORTANT TO USE THE CORRECT VALID FILE AND NOT A TEST FILE AT THIS STAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Inference on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 ./cellvit/training/evaluate/inference_cellvit_experiment_midog.py \\\n",
    "#     --logdir /Path/to/your/run/log \\\n",
    "#     --graph_path /Path/to/the/graphs \\\n",
    "#     --test_filelist /Path/to/the/test/split.csv \\ # e.g. ./logs/Datasets/MIDOG++/split/test_files/test_all.csv\n",
    "#     --gt_json /Path/to/gt_test.json \\\n",
    "#     --x_valid_path /Path/to/datasets_xvalidation.csv \\\n",
    "#     --threshold # e.g. 0.85, take it from your best threshold out of the validation folder\n",
    "# IT IS IMPORTANT TO USE THE CORRECT TEST FILE AND NOT A VALID FILE AT THIS STAGE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellvit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
